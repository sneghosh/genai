{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a320695-af6a-422f-871c-106393b80e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HomePC\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a distant galaxy, the sun was a star that was once a very distant star. Its diameter was about the same as the diameter of the Sun and its radius about a billion light-years. It was also the only one of its kind that could be observed in our galaxy. The universe had been expanding for millions of years and had begun to settle into its new form. Now, as our planet was expanding, it was gradually losing its mass. When the stars of this\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize model and tokenizer for GPT-2\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Input prompt\n",
    "input_text = \"Once upon a time in a distant galaxy,\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Define generation settings for more control and creativity\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=100,          # Generate up to 100 tokens in total\n",
    "    num_return_sequences=1,   # Number of generated sequences\n",
    "    no_repeat_ngram_size=2,   # Prevent repetition of 2-grams (pairs of words)\n",
    "    temperature=0.7,          # Lower values make the output more focused; higher values add creativity\n",
    "    top_k=50,                 # Limits sampling to the top 50 tokens to reduce randomness\n",
    "    top_p=0.9,                # Enables nucleus sampling: tokens with a cumulative probability of 0.9 are considered\n",
    "    do_sample=True            # Enables sampling (more random than greedy decoding)\n",
    ")\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6762e2-31b1-41bb-8fbb-99e3f876060d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
